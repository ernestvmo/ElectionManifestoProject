{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import string\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.nl.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain, LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('nl_core_news_lg')\n",
    "stops_words = STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = ['1986', '1994', '1998']\n",
    "SELECTED_YEAR = 0 # for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple theme taxonomy exrtaction method: take all themes and ignore the relationship between themes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex list that captures the relation between themes (not complete yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomy = {}\n",
    "# for theme in taxonomy_xml.getroot():\n",
    "#     tax = {}\n",
    "#     # print(theme)\n",
    "#     for sub in theme:\n",
    "#         for subsub in sub:\n",
    "#             if sub.tag == 'related_themes':\n",
    "#                 print('RELATED', subsub.get('id'))\n",
    "#             else:\n",
    "#                 print('REFERRES', subsub.text)\n",
    "#             # print(subsub.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = xml.dom.minidom.parse(f'data/Political_election_manifestos/VP_{year[SELECTED_YEAR]}.party-topicnr-content.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_text_preprocessing(text: str):\n",
    "    # Strip + Lower case\n",
    "    text = text.strip().lower()\n",
    "    # Remove digits\n",
    "    text = unidecode.unidecode(text)\n",
    "    # Remove Punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #  Remove stop words and Lemmatisation\n",
    "    text = ' '.join([token.lemma_ for token in nlp(text) if token.is_stop == False and token.text != ' '])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = {}\n",
    "for chapter in document.firstChild.getElementsByTagName('chapter'):\n",
    "    party = chapter.getAttribute('party')\n",
    "    # print(chapter.getAttribute('party'))\n",
    "    par = {}\n",
    "    for paragraph in chapter.getElementsByTagName('p'):\n",
    "        id = paragraph.getAttribute('id')\n",
    "        # print(paragraph.getAttribute('id'))\n",
    "        \n",
    "        paragraph_value = paragraph.childNodes[2].nodeValue\n",
    "        # paragraph_value = apply_text_preprocessing(paragraph_value)\n",
    "        # print(paragraph_value)\n",
    "\n",
    "        paragraph_themes = [theme.getAttribute('id') for theme in paragraph.getElementsByTagName('theme')]\n",
    "        # print(paragraph_themes)\n",
    "\n",
    "        par[id] = {'p': paragraph_value, 'themes': paragraph_themes}\n",
    "    chapters[party] = par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for chapter in chapters.keys():\n",
    "    for text in chapters[chapter].keys():\n",
    "        # if chapters[chapter][text]['p'] != '':\n",
    "        X.append(chapters[chapter][text]['p']) \n",
    "        y.append(chapters[chapter][text]['themes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797\n",
      "797\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting All Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomy_xml = ET.parse(f'data/Political_election_manifestos/taxonomy.{year[SELECTED_YEAR]}.xml')\n",
    "taxonomy_xml = xml.dom.minidom.parse(f'data/Political_election_manifestos/taxonomy.{year[SELECTED_YEAR]}.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE THEME COLLECTION\n",
    "themes_set = set()\n",
    "for theme in taxonomy_xml.getElementsByTagName('theme'):\n",
    "    themes_set.add(theme.getAttribute('id'))\n",
    "# them we want to combine this themes list with the themes present in the manifesto\n",
    "for elem in y:\n",
    "    for sub_elem in elem:\n",
    "        themes_set.add(sub_elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_bin = MultiLabelBinarizer()\n",
    "multilabel_bin.fit_transform([themes_set])\n",
    "y_bin = multilabel_bin.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play around with n_gram and max_features\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2', max_features = 10000)\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BinaryRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_bin, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_classifier = LabelPowerset(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_preds = lp_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27238805970149255\n",
      "0.026258992805755395\n",
      "0.047900262467191604\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, lp_preds, average='micro'))\n",
    "print(recall_score(y_test, lp_preds, average='micro'))\n",
    "print(f1_score(y_test, lp_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION 0.37753510140405616\n",
      "RECALL 0.26115107913669067\n",
      "F1 0.308739102700404\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_preds = dt.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, dt_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, dt_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, dt_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION 0.8773946360153256\n",
      "RECALL 0.08237410071942446\n",
      "F1 0.15060835251561985\n"
     ]
    }
   ],
   "source": [
    "exts = ExtraTreesClassifier()\n",
    "exts.fit(X_train, y_train)\n",
    "exts_preds = exts.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, exts_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, exts_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, exts_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION 0.9111111111111111\n",
      "RECALL 0.014748201438848921\n",
      "F1 0.029026548672566373\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, knn_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, knn_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, knn_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION 0.7726737338044759\n",
      "RECALL 0.23597122302158274\n",
      "F1 0.36153210250757783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_preds = mlp.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, mlp_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, mlp_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, mlp_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "PRECISION 0.0\n",
      "RECALL 0.0\n",
      "F1 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rnn = RadiusNeighborsClassifier(radius=1.5)\n",
    "rnn.fit(X_train, y_train)\n",
    "print(rnn.score(X_test, y_test))\n",
    "rnn_preds = rnn.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, rnn_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, rnn_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, rnn_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION 0.874439461883408\n",
      "RECALL 0.07014388489208633\n",
      "F1 0.12987012987012986\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, rf_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, rf_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, rf_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (533, 234) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/5wf6r0p14r38dgytvnyprf9r0000gn/T/ipykernel_27443/31397530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mridge_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PRECISION'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mridge_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RECALL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mridge_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1025\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (533, 234) instead."
     ]
    }
   ],
   "source": [
    "ridge = GradientBoostingClassifier()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_preds = ridge.predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, ridge_preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, ridge_preds, average='micro'))\n",
    "print('F1', f1_score(y_test, ridge_preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION 0.8836206896551724\n",
      "RECALL 0.1474820143884892\n",
      "F1 0.25277435265104814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "multi_forest = ClassifierChain(RandomForestClassifier(), order='random')\n",
    "preds = multi_forest.fit(X_train, y_train).predict(X_test)\n",
    "print('PRECISION', precision_score(y_test, preds, average='micro'))\n",
    "print('RECALL', recall_score(y_test, preds, average='micro'))\n",
    "print('F1', f1_score(y_test, preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
