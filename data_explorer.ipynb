{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import string\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.nl.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain, LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('nl_core_news_lg')\n",
    "stops_words = STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = ['1986', '1994', '1998']\n",
    "SELECTED_YEAR = 0 # for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple theme taxonomy exrtaction method: take all themes and ignore the relationship between themes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex list that captures the relation between themes (not complete yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomy = {}\n",
    "# for theme in taxonomy_xml.getroot():\n",
    "#     tax = {}\n",
    "#     # print(theme)\n",
    "#     for sub in theme:\n",
    "#         for subsub in sub:\n",
    "#             if sub.tag == 'related_themes':\n",
    "#                 print('RELATED', subsub.get('id'))\n",
    "#             else:\n",
    "#                 print('REFERRES', subsub.text)\n",
    "#             # print(subsub.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = xml.dom.minidom.parse(f'data/Political_election_manifestos/VP_{year[SELECTED_YEAR]}.party-topicnr-content.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_text_preprocessing(text: str):\n",
    "    # Strip + Lower case\n",
    "    text = text.strip().lower()\n",
    "    # Remove digits\n",
    "    text = unidecode.unidecode(text)\n",
    "    # Remove Punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    #  Remove stop words and Lemmatisation\n",
    "    text = ' '.join([token.lemma_ for token in nlp(text) if token.is_stop == False and token.text != ' '])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = {}\n",
    "for chapter in document.firstChild.getElementsByTagName('chapter'):\n",
    "    party = chapter.getAttribute('party')\n",
    "    # print(chapter.getAttribute('party'))\n",
    "    par = {}\n",
    "    for paragraph in chapter.getElementsByTagName('p'):\n",
    "        id = paragraph.getAttribute('id')\n",
    "        # print(paragraph.getAttribute('id'))\n",
    "        \n",
    "        paragraph_value = paragraph.childNodes[2].nodeValue\n",
    "        # paragraph_value = apply_text_preprocessing(paragraph_value)\n",
    "        # print(paragraph_value)\n",
    "\n",
    "        paragraph_themes = [theme.getAttribute('id').lower() for theme in paragraph.getElementsByTagName('theme')]\n",
    "        # print(paragraph_themes)\n",
    "\n",
    "        par[id] = {'p': paragraph_value, 'themes': paragraph_themes}\n",
    "    chapters[party] = par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for chapter in chapters.keys():\n",
    "    for text in chapters[chapter].keys():\n",
    "        # if chapters[chapter][text]['p'] != '':\n",
    "        X.append(chapters[chapter][text]['p']) \n",
    "        y.append(chapters[chapter][text]['themes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797\n",
      "797\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting All Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxonomy_xml = ET.parse(f'data/Political_election_manifestos/taxonomy.{year[SELECTED_YEAR]}.xml')\n",
    "taxonomy_xml = xml.dom.minidom.parse(f'data/Political_election_manifestos/taxonomy.{year[SELECTED_YEAR]}.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE THEME COLLECTION\n",
    "themes_set = set()\n",
    "for theme in taxonomy_xml.getElementsByTagName('theme'):\n",
    "    themes_set.add(theme.getAttribute('id').lower())\n",
    "# them we want to combine this themes list with the themes present in the manifesto\n",
    "for elem in y:\n",
    "    for sub_elem in elem:\n",
    "        themes_set.add(sub_elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_bin = MultiLabelBinarizer()\n",
    "multilabel_bin.fit_transform([themes_set])\n",
    "y_bin = multilabel_bin.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play around with n_gram and max_features\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2', max_features = 10000)\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_bin, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_relevance(model, X_train, y_train, X_test, y_test):\n",
    "    bn_model = BinaryRelevance(model)\n",
    "    bn_model.fit(X_train, y_train)\n",
    "    preds = bn_model.predict(X_test)\n",
    "    print('Precision score:', precision_score(y_test, preds, average='micro'))\n",
    "    print('Recall score:', recall_score(y_test, preds, average='micro'))\n",
    "    print('F1 score:', f1_score(y_test, preds, average='micro'))\n",
    "    print('Hamming distance:', hamming_loss(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9305555555555556\n",
      "Recall score: 0.02410071942446043\n",
      "F1 score: 0.046984572230014024\n",
      "Hamming distance: 0.043997668997669\n"
     ]
    }
   ],
   "source": [
    "binary_relevance(MultinomialNB(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.5421127765881513\n",
      "Recall score: 0.5464028776978417\n",
      "F1 score: 0.5442493729845933\n",
      "Hamming distance: 0.041181041181041184\n"
     ]
    }
   ],
   "source": [
    "binary_relevance(DecisionTreeClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8700564971751412\n",
      "Recall score: 0.22158273381294963\n",
      "F1 score: 0.35321100917431186\n",
      "Hamming distance: 0.03651903651903652\n"
     ]
    }
   ],
   "source": [
    "binary_relevance(ExtraTreesClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.8721934369602763\n",
      "Recall score: 0.18165467625899281\n",
      "F1 score: 0.30068472759749926\n",
      "Hamming distance: 0.03802447552447553\n"
     ]
    }
   ],
   "source": [
    "binary_relevance(RandomForestClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.7948717948717948\n",
      "Recall score: 0.05575539568345324\n",
      "F1 score: 0.10420168067226891\n",
      "Hamming distance: 0.04313973063973064\n"
     ]
    }
   ],
   "source": [
    "binary_relevance(KNeighborsClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_relevance(MLPClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_chaining(model, X_train, y_train, X_test, y_test):\n",
    "    cc_model = ClassifierChain(model)\n",
    "    cc_model.fit(X_train, y_train)\n",
    "    preds = cc_model.predict(X_test)\n",
    "    print('Precision score:', precision_score(y_test, preds, average='micro'))\n",
    "    print('Recall score:', recall_score(y_test, preds, average='micro'))\n",
    "    print('F1 score:', f1_score(y_test, preds, average='micro'))\n",
    "    print('Hamming distance:', hamming_loss(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chaining(MultinomialNB(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chaining(DecisionTreeClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chaining(ExtraTreesClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chaining(RandomForestClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chaining(KNeighborsClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_chaining(MLPClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_powerset(model, X_train, y_train, X_test, y_test):\n",
    "    cc_model = LabelPowerset(model)\n",
    "    cc_model.fit(X_train, y_train)\n",
    "    preds = cc_model.predict(X_test)\n",
    "    print('Precision score:', precision_score(y_test, preds, average='micro'))\n",
    "    print('Recall score:', recall_score(y_test, preds, average='micro'))\n",
    "    print('F1 score:', f1_score(y_test, preds, average='micro'))\n",
    "    print('Hamming distance:', hamming_loss(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_powerset(MultinomialNB(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_powerset(DecisionTreeClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_powerset(ExtraTreesClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_powerset(RandomForestClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_powerset(KNeighborsClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_powerset(MLPClassifier(), X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
